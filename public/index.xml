<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Thoughts and Notes</title>
    <link>http://localhost:1313/writings/</link>
    <description>Recent content on Thoughts and Notes</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 05 Apr 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/writings/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Papers</title>
      <link>http://localhost:1313/writings/posts/papers/all_papers/</link>
      <pubDate>Fri, 05 Apr 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/writings/posts/papers/all_papers/</guid>
      <description>&lt;h2 id=&#34;embeddings-constrained&#34;&gt;Embeddings constrained&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://localhost:1313/writings/posts/papers/individual_papers/memory_augmentation_multimodal_mobile/&#34;&gt;Memory Augmentation via Mobile Multimodal Embedding, 2025&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;activation-functions&#34;&gt;Activation functions&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2503.10622&#34;&gt;Dynamic Tanh, 2025&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;llm-finetuning&#34;&gt;LLM Finetuning&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://aclanthology.org/2024.emnlp-main.444.pdf&#34;&gt;FT on Knowledge Encourage Hallucinations, 2024, Google&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.arxiv.org/pdf/2508.09494&#34;&gt;Learning Facts at Scale with Active Reading, 2025, Meta&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>Memory Augmentation via Mobile Multimodal Embedding</title>
      <link>http://localhost:1313/writings/posts/papers/individual_papers/memory_augmentation_multimodal_mobile/</link>
      <pubDate>Tue, 05 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/writings/posts/papers/individual_papers/memory_augmentation_multimodal_mobile/</guid>
      <description>&lt;h2 id=&#34;memory-augmentation-via-mobile-multimodal-embedding-2025&#34;&gt;Memory augmentation via mobile multimodal embedding, 2025&lt;/h2&gt;&#xA;&lt;h3 id=&#34;reference&#34;&gt;Reference&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Paper: &lt;a href=&#34;https://www.nature.com/articles/s41467-025-60802-5&#34;&gt;https://www.nature.com/articles/s41467-025-60802-5&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://pmc.ncbi.nlm.nih.gov/articles/instance/12179270/bin/41467_2025_60802_MOESM1_ESM.pdf&#34;&gt;Supplementary material&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/caidongqi/Mobile-Search-Engine/tree/pc&#34;&gt;Code&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;overview&#34;&gt;Overview&lt;/h3&gt;&#xA;&lt;p&gt;Shares a new approach to multi-modal embeddings on a resource constrained device, such as your smartphone, relative to cloud.&lt;/p&gt;&#xA;&lt;h3 id=&#34;diagrams&#34;&gt;Diagrams&lt;/h3&gt;&#xA;&lt;p&gt;&lt;img src=&#34;./reminesce_architecture.png&#34; alt=&#34;architecture&#34;&gt;&#xA;&lt;img src=&#34;./reminesce_workflow.png&#34; alt=&#34;workflow&#34;&gt;&lt;/p&gt;&#xA;&lt;h3 id=&#34;whats-new&#34;&gt;What&amp;rsquo;s new&lt;/h3&gt;&#xA;&lt;p&gt;The core idea is to generate &amp;ldquo;coarse-grained embeddings&amp;rdquo; via a predictor-guided early-exit strategy to efficiently identify likely candidates during retrieval, while using lightweight adapters and refined retrieval to maintain accuracy. The framework is aptly named &amp;ldquo;Reminisce&amp;rdquo;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>sigmoid</title>
      <link>http://localhost:1313/writings/posts/activation_functions/sigmoid/</link>
      <pubDate>Tue, 05 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/writings/posts/activation_functions/sigmoid/</guid>
      <description>&lt;h1 id=&#34;sigmoid&#34;&gt;Sigmoid&lt;/h1&gt;&#xA;&lt;p&gt;The sigmoid function can be defined as:&lt;/p&gt;&#xA;&lt;p&gt;f(x) = 1 / (1 + e^(-x))&lt;/p&gt;&#xA;&lt;p&gt;Where:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;f(x) is the output of the sigmoid function for input x&lt;/li&gt;&#xA;&lt;li&gt;e is the Euler’s number (approximately 2.71828)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;⠀ In Python, the sigmoid function can be implemented as follows:&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; math&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sigmoid&lt;/span&gt;(x):&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; math&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;exp(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;x))&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This function takes an input x and returns the output of the sigmoid function for that input.&lt;/p&gt;&#xA;&lt;h2 id=&#34;activation-functions&#34;&gt;activation-functions&lt;/h2&gt;&#xA;&lt;p&gt;GELU&lt;/p&gt;</description>
    </item>
    <item>
      <title>Types</title>
      <link>http://localhost:1313/writings/posts/activation_functions/types/</link>
      <pubDate>Tue, 05 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/writings/posts/activation_functions/types/</guid>
      <description>&lt;h1 id=&#34;types-of-activation-functions&#34;&gt;Types of activation functions&lt;/h1&gt;&#xA;&lt;h2 id=&#34;comparison&#34;&gt;Comparison&lt;/h2&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;&lt;strong&gt;Activation Function&lt;/strong&gt;&lt;/th&gt;&#xA;          &lt;th&gt;&lt;strong&gt;Pros&lt;/strong&gt;&lt;/th&gt;&#xA;          &lt;th&gt;&lt;strong&gt;Cons&lt;/strong&gt;&lt;/th&gt;&#xA;          &lt;th&gt;&lt;strong&gt;Used In LLMs&lt;/strong&gt;&lt;/th&gt;&#xA;          &lt;th&gt;&lt;strong&gt;Common Use Cases&lt;/strong&gt;&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Sigmoid&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Smooth, probabilistic output between (0,1)&lt;/td&gt;&#xA;          &lt;td&gt;Vanishing gradient, not zero-centered&lt;/td&gt;&#xA;          &lt;td&gt;None (not used in modern LLMs)&lt;/td&gt;&#xA;          &lt;td&gt;Binary classification (non-LLM)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Softmax&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Normalized output probabilities&lt;/td&gt;&#xA;          &lt;td&gt;Sensitive to large input values&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;All LLMs (e.g., GPT, BERT, LLaMA, T5, Claude, Gemini, PaLM)&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Final output/token prediction&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Hard Sigmoid/Swish&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Low compute, approximates sigmoid/swish&lt;/td&gt;&#xA;          &lt;td&gt;Less precise&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;MobileBERT, TinyBERT, DistilBERT (quantized/edge LLMs)&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Edge/NLP deployment&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Tanh&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Zero-centered, smooth gradient&lt;/td&gt;&#xA;          &lt;td&gt;Vanishing gradients at extremes&lt;/td&gt;&#xA;          &lt;td&gt;Early LSTM-based LLMs (e.g., early Seq2Seq models)&lt;/td&gt;&#xA;          &lt;td&gt;Historical LLMs, RNN-based&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Dynamic Tanh&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Adaptive shape, better expressiveness&lt;/td&gt;&#xA;          &lt;td&gt;More parameters, added complexity&lt;/td&gt;&#xA;          &lt;td&gt;Experimental adaptive LLMs (research only)&lt;/td&gt;&#xA;          &lt;td&gt;Meta-learning, adaptive time-series&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;ReLU&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Efficient, avoids vanishing gradient for positive inputs&lt;/td&gt;&#xA;          &lt;td&gt;Dying ReLU problem&lt;/td&gt;&#xA;          &lt;td&gt;Rare; used in early transformer variants (e.g., Transformer-XL)&lt;/td&gt;&#xA;          &lt;td&gt;Legacy LLM components&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Leaky ReLU&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Mitigates dying ReLU issue&lt;/td&gt;&#xA;          &lt;td&gt;Slightly more complex than ReLU&lt;/td&gt;&#xA;          &lt;td&gt;Rare in LLMs; minor experimentation (e.g., early GShard)&lt;/td&gt;&#xA;          &lt;td&gt;Not typical in production LLMs&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Parametric ReLU (PReLU)&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Learns slope of negative input&lt;/td&gt;&#xA;          &lt;td&gt;Risk of overfitting, adds parameters&lt;/td&gt;&#xA;          &lt;td&gt;Rare, mostly experimental in LLMs&lt;/td&gt;&#xA;          &lt;td&gt;Not standard in transformer LLMs&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;ELU&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Smooth for negative inputs, zero-centered&lt;/td&gt;&#xA;          &lt;td&gt;Higher compute cost&lt;/td&gt;&#xA;          &lt;td&gt;Not used in LLMs&lt;/td&gt;&#xA;          &lt;td&gt;Not applicable&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;Swish&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Smooth, non-monotonic, better than ReLU in some cases&lt;/td&gt;&#xA;          &lt;td&gt;More computation&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;T5, Switch Transformer, GShard&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;NLP transformer blocks&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;strong&gt;GELU&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Smooth, noise-tolerant, better convergence&lt;/td&gt;&#xA;          &lt;td&gt;Computationally intensive&lt;/td&gt;&#xA;          &lt;td&gt;&lt;strong&gt;GPT-2, GPT-3, GPT-4, BERT, RoBERTa, T5, LLaMA, OPT, BLOOM, Mistral, Falcon&lt;/strong&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Feedforward layers in LLMs&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;h2 id=&#34;sigmoid&#34;&gt;Sigmoid&lt;/h2&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; math&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;sigmoid&lt;/span&gt;(x):&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; math&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;exp(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;x))&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;softmax&#34;&gt;Softmax&lt;/h2&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; np&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;softmax&lt;/span&gt;(x):&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    exp_x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;exp(x &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;max(x))&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    res &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; exp_x &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum(exp_x, axis&lt;span style=&#34;color:#f92672&#34;&gt;=-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, keepdims&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; res&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;hard-sigmoidswish&#34;&gt;Hard sigmoid/swish&lt;/h2&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; math&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;hard_sigmoid_swish&lt;/span&gt;(x):&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    res &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;clip((x &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; res&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;tanh&#34;&gt;Tanh&lt;/h2&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;tanh&lt;/span&gt;(x):&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; (np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;exp(x) &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;exp(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;x)) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; (np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;exp(x) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;exp(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;x))&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;dynamic-tanh&#34;&gt;Dynamic Tanh&lt;/h2&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;DyTanh&lt;/span&gt;(x, gamma, alpha , beta):&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;     &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    alpha_x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; alpha &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; x&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    res &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; gamma &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tanh(alpha_x) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; beta&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; res&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# alpha is a learnable scalar parameter &lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# that allows scaling the input differently based on its range, accounting  for varying x scale&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# &lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# gamma, beta are learnable, per-channel vector parameters, &lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# the same as those used in all normalization layers&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# they allow the output to scale back to any scales.&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Reference&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
