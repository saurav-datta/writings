<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Embeddings_contrained on Thoughts and Notes</title>
    <link>http://localhost:1313/tags/embeddings_contrained/</link>
    <description>Recent content in Embeddings_contrained on Thoughts and Notes</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 05 Mar 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/embeddings_contrained/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Embeddings Contrained</title>
      <link>http://localhost:1313/posts/papers/embeddings_constrained/</link>
      <pubDate>Tue, 05 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/papers/embeddings_constrained/</guid>
      <description>&lt;h2 id=&#34;memory-augmentation-via-mobile-multimodal-embedding-2025&#34;&gt;Memory augmentation via mobile multimodal embedding, 2025&lt;/h2&gt;&#xA;&lt;h3 id=&#34;reference&#34;&gt;Reference&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Paper: &lt;a href=&#34;https://www.nature.com/articles/s41467-025-60802-5&#34;&gt;https://www.nature.com/articles/s41467-025-60802-5&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://pmc.ncbi.nlm.nih.gov/articles/instance/12179270/bin/41467_2025_60802_MOESM1_ESM.pdf&#34;&gt;Supplementary material&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/caidongqi/Mobile-Search-Engine/tree/pc&#34;&gt;Code&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;overview&#34;&gt;Overview&lt;/h3&gt;&#xA;&lt;p&gt;Shares a new approach to multi-modal embeddings on a resource constrained device, such as your smartphone, relative to cloud.&lt;/p&gt;&#xA;&lt;h3 id=&#34;diagrams&#34;&gt;Diagrams&lt;/h3&gt;&#xA;&lt;p&gt;{{ $image := .Resources.Get &amp;ldquo;reminesce_architecture.png&amp;rdquo; }}&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;./reminesce_architecture.png&#34; alt=&#34;architecture&#34;&gt;&#xA;&lt;img src=&#34;./reminesce_workflow.png&#34; alt=&#34;workflow&#34;&gt;&lt;/p&gt;&#xA;&lt;h3 id=&#34;whats-new&#34;&gt;What&amp;rsquo;s new&lt;/h3&gt;&#xA;&lt;p&gt;The core idea is to generate &amp;ldquo;coarse-grained embeddings&amp;rdquo; via a predictor-guided early-exit strategy to efficiently identify likely candidates during retrieval, while using lightweight adapters and refined retrieval to maintain accuracy. The framework is aptly named &amp;ldquo;Reminisce&amp;rdquo;.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
